{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MIA Features\n",
    "\n",
    "Based on di.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare_model\n",
    "from metrics import aggregate_metrics, reference_model_registry\n",
    "import json, os\n",
    "import argparse\n",
    "from datasets import load_dataset\n",
    "from dataloader import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"EleutherAI/pythia-410m-deduped\"\n",
    "model_name = \"EleutherAI/pythia-2.8b\"\n",
    "cache_dir = \"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d8d6f35b2445a28ea2713123985fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6259afef70d34d99b5cfe9a801cd8913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b437aaf091c74963be0c4e6eb85835bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b68853241f45238b1a28529a4ab1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cdde2a5b754ddfbf98da19dfd5529c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = prepare_model(model_name, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"haritzpuerto/the_pile_arxiv_1k_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Aggregate Features with MIAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pile_train = ds['train'].select(range(1000))\n",
    "pile_val = ds['validation'].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [\"k_min_probs\", \"ppl\", \"zlib_ratio\", \"k_max_probs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:13<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "metrics_train = aggregate_metrics(model, tokenizer, pile_train, metric_list, None, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metrics_train['ppl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:12<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "metrics_val = aggregate_metrics(model, tokenizer, pile_val, metric_list, None, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Learn MIA Correlations\n",
    "\n",
    "In this stage, we train a linear regressor to learn the importance of weights for different MIA attacks to use for the final dataset inference procedure. \n",
    "\n",
    "Across each MIA feature value, we first modify the top 5% outliers by changing their values to the mean of the distribution. This step is crucial to prevent issues in Step 3, where the model might learn skewed correlations due to a few outlier samples. \n",
    "\n",
    "We then pass the data through a linear regression model to learn weights for each feature.\n",
    "All ‘suspect’ samples in Asus are labeled as 0, and all validation samples in Aval are labeled as 1.\n",
    "\n",
    "A regressor is trained to predict the label given the samples, effectively learning the correlation between the features\n",
    "and their membership status.\n",
    "\n",
    "Based on the linear_di.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, chi2, norm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from selected_features import feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(metrics):\n",
    "    keys = list(metrics.keys())\n",
    "    num_elements = len(metrics[keys[0]])\n",
    "    print (f\"Using {num_elements} elements\")\n",
    "    # select a random subset of val_metrics (50% of ids)\n",
    "    ids_train = np.random.choice(num_elements, num_elements//2, replace=False)\n",
    "    ids_val = np.array([i for i in range(num_elements) if i not in ids_train])\n",
    "    new_metrics_train = {}\n",
    "    new_metrics_val = {}\n",
    "    for key in keys:\n",
    "        new_metrics_train[key] = np.array(metrics[key])[ids_train]\n",
    "        new_metrics_val[key] = np.array(metrics[key])[ids_val]\n",
    "    return new_metrics_train, new_metrics_val\n",
    "\n",
    "def remove_outliers(metrics, remove_frac=0.05, outliers = \"zero\"):\n",
    "    # Sort the array to work with ordered data\n",
    "    sorted_ids = np.argsort(metrics)\n",
    "    \n",
    "    # Calculate the number of elements to remove from each side\n",
    "    total_elements = len(metrics)\n",
    "    elements_to_remove_each_side = int(total_elements * remove_frac / 2) \n",
    "    \n",
    "    # Ensure we're not attempting to remove more elements than are present\n",
    "    if elements_to_remove_each_side * 2 > total_elements:\n",
    "        raise ValueError(\"remove_frac is too large, resulting in no elements left.\")\n",
    "    \n",
    "    # Change the removed metrics to 0.\n",
    "    lowest_ids = sorted_ids[:elements_to_remove_each_side]\n",
    "    highest_ids = sorted_ids[-elements_to_remove_each_side:]\n",
    "    all_ids = np.concatenate((lowest_ids, highest_ids))\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    \n",
    "    trimmed_metrics = np.copy(metrics)\n",
    "    \n",
    "    if outliers == \"zero\":\n",
    "        trimmed_metrics[all_ids] = 0\n",
    "    elif outliers == \"mean\" or outliers == \"mean+p-value\":\n",
    "        trimmed_metrics[all_ids] = np.mean(trimmed_metrics)\n",
    "    elif outliers == \"clip\":\n",
    "        highest_val_permissible = trimmed_metrics[highest_ids[0]]\n",
    "        lowest_val_permissible = trimmed_metrics[lowest_ids[-1]]\n",
    "        trimmed_metrics[highest_ids] =  highest_val_permissible\n",
    "        trimmed_metrics[lowest_ids] =   lowest_val_permissible\n",
    "    elif outliers == \"randomize\":\n",
    "        #this will randomize the order of metrics\n",
    "        trimmed_metrics = np.delete(trimmed_metrics, all_ids)\n",
    "    else:\n",
    "        assert outliers in [\"keep\", \"p-value\"]\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    return trimmed_metrics\n",
    "\n",
    "def normalize_and_stack(train_metrics, val_metrics, normalize=\"train\"):\n",
    "    '''\n",
    "    excpects an input list of list of metrics\n",
    "    normalize val with corre\n",
    "    '''\n",
    "    new_train_metrics = []\n",
    "    new_val_metrics = []\n",
    "    for (tm, vm) in zip(train_metrics, val_metrics):\n",
    "        if normalize == \"combined\":\n",
    "            combined_m = np.concatenate((tm, vm))\n",
    "            mean_tm = np.mean(combined_m)\n",
    "            std_tm = np.std(combined_m)\n",
    "        else:\n",
    "            mean_tm = np.mean(tm)\n",
    "            std_tm = np.std(tm)\n",
    "        \n",
    "        if normalize == \"no\":\n",
    "            normalized_vm = vm\n",
    "            normalized_tm = tm\n",
    "        else:\n",
    "            #normalization should be done with respect to the train set statistics\n",
    "            normalized_vm = (vm - mean_tm) / std_tm\n",
    "            normalized_tm = (tm - mean_tm) / std_tm\n",
    "        \n",
    "        new_train_metrics.append(normalized_tm)\n",
    "        new_val_metrics.append(normalized_vm)\n",
    "\n",
    "    train_metrics = np.stack(new_train_metrics, axis=1)\n",
    "    val_metrics = np.stack(new_val_metrics, axis=1)\n",
    "    return train_metrics, val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1 Remove Outliers\n",
    "\n",
    "Across each MIA feature value, we first modify the top 5% outliers by changing their values to the mean of the distribution. This step is crucial to prevent issues in Step 3, where the model might learn skewed correlations due to a few outlier samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "\n",
    "outliers = \"clip\" #  choices=[\"randomize\", \"keep\", \"zero\", \"mean\", \"clip\", \"mean+p-value\", \"p-value\"]\n",
    "\n",
    "keys = list(metrics_train.keys())\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "for key in keys:\n",
    "    metrics_train_key = np.array(metrics_train[key])\n",
    "    metrics_val_key = np.array(metrics_val[key])\n",
    "\n",
    "    # remove the top 2.5% and bottom 2.5% of the data\n",
    "    \n",
    "    metrics_train_key = remove_outliers(metrics_train_key, remove_frac = 0.05, outliers = outliers)\n",
    "    metrics_val_key = remove_outliers(metrics_val_key, remove_frac = 0.05, outliers = outliers)\n",
    "\n",
    "    train_metrics.append(metrics_train_key)\n",
    "    val_metrics.append(metrics_val_key)\n",
    "\n",
    "# concatenate the train and val metrics by stacking them\n",
    "\n",
    "# train_metrics, val_metrics = new_train_metrics, new_val_metrics\n",
    "train_metrics, val_metrics = normalize_and_stack(train_metrics, val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ppl',\n",
       " 'k_min_probs_0.05',\n",
       " 'k_min_probs_0.1',\n",
       " 'k_min_probs_0.2',\n",
       " 'k_min_probs_0.3',\n",
       " 'k_min_probs_0.4',\n",
       " 'k_min_probs_0.5',\n",
       " 'k_min_probs_0.6',\n",
       " 'k_max_probs_0.05',\n",
       " 'k_max_probs_0.1',\n",
       " 'k_max_probs_0.2',\n",
       " 'k_max_probs_0.3',\n",
       " 'k_max_probs_0.4',\n",
       " 'k_max_probs_0.5',\n",
       " 'k_max_probs_0.6',\n",
       " 'zlib_ratio']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16)\n",
      "(999, 16)\n"
     ]
    }
   ],
   "source": [
    "print(train_metrics.shape)\n",
    "print(val_metrics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux function\n",
    "def get_dataset_splits(_train_metrics, _val_metrics, num_samples):\n",
    "    # get the train and val sets\n",
    "    for_train_train_metrics = _train_metrics[:num_samples]\n",
    "    for_train_val_metrics = _val_metrics[:num_samples]\n",
    "    for_val_train_metrics = _train_metrics[num_samples:]\n",
    "    for_val_val_metrics = _val_metrics[num_samples:]\n",
    "\n",
    "\n",
    "    # create the train and val sets\n",
    "    train_x = np.concatenate((for_train_train_metrics, for_train_val_metrics), axis=0)\n",
    "    train_y = np.concatenate((-1*np.zeros(for_train_train_metrics.shape[0]), np.ones(for_train_val_metrics.shape[0])))\n",
    "    val_x = np.concatenate((for_val_train_metrics, for_val_val_metrics), axis=0)\n",
    "    val_y = np.concatenate((-1*np.zeros(for_val_train_metrics.shape[0]), np.ones(for_val_val_metrics.shape[0])))\n",
    "    \n",
    "    # return tensors\n",
    "    train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "    train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "    val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "    val_y = torch.tensor(val_y, dtype=torch.float32)\n",
    "    \n",
    "    return (train_x, train_y), (val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux functions about MIA classifier\n",
    "\n",
    "def train_model(inputs, y, num_epochs=10000):\n",
    "    num_features = inputs.shape[1]\n",
    "    model = get_model(num_features)\n",
    "        \n",
    "    criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy Loss for binary classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Convert y to float tensor for BCEWithLogitsLoss\n",
    "    y_float = y.float()\n",
    "\n",
    "    with tqdm(range(num_epochs)) as pbar:\n",
    "        for epoch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()  # Squeeze the output to remove singleton dimension\n",
    "            loss = criterion(outputs, y_float)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_description('loss {}'.format(loss.item()))\n",
    "    return model\n",
    "\n",
    "def get_model(num_features, linear = True):\n",
    "    if linear:\n",
    "        model = nn.Linear(num_features, 1)\n",
    "    else:\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(num_features, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)  # Single output neuron\n",
    "        )\n",
    "    return model\n",
    "\n",
    "def get_predictions(model, val, y):\n",
    "    with torch.no_grad():\n",
    "        preds = model(val).detach().squeeze()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = criterion(preds, y.float())\n",
    "    return preds.numpy(), loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: Learn the weights of each feature\n",
    "\n",
    "We then pass the data through a linear regression model to learn weights for each feature.\n",
    "\n",
    "All ‘suspect’ samples in Asus are labeled as 0, and all validation samples in Aval are labeled as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux functions about p-values\n",
    "list_number_samples = [2, 5, 10, 20, 50, 100, 150, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "def get_p_value_list(heldout_train, heldout_val, list_number_samples):\n",
    "    # list_number_samples is used to see how the p-values changes across different number of samples\n",
    "    p_value_list = []\n",
    "    for num_samples in list_number_samples:\n",
    "        heldout_train_curr = heldout_train[:num_samples]\n",
    "        heldout_val_curr = heldout_val[:num_samples]\n",
    "        t, p_value = ttest_ind(heldout_train_curr, heldout_val_curr, alternative='less')\n",
    "        p_value_list.append(p_value)\n",
    "    return p_value_list\n",
    "    \n",
    "    \n",
    "\n",
    "def split_train_val(metrics):\n",
    "    keys = list(metrics.keys())\n",
    "    num_elements = len(metrics[keys[0]])\n",
    "    print (f\"Using {num_elements} elements\")\n",
    "    # select a random subset of val_metrics (50% of ids)\n",
    "    ids_train = np.random.choice(num_elements, num_elements//2, replace=False)\n",
    "    ids_val = np.array([i for i in range(num_elements) if i not in ids_train])\n",
    "    new_metrics_train = {}\n",
    "    new_metrics_val = {}\n",
    "    for key in keys:\n",
    "        new_metrics_train[key] = np.array(metrics[key])[ids_train]\n",
    "        new_metrics_val[key] = np.array(metrics[key])[ids_val]\n",
    "    return new_metrics_train, new_metrics_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.6831618547439575: 100%|██████████| 1000/1000 [00:01<00:00, 514.16it/s]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 500 # How many samples to use for training and validation?\n",
    "\n",
    "np.random.shuffle(train_metrics)\n",
    "np.random.shuffle(val_metrics)\n",
    "\n",
    "# train a model by creating a train set and a held out set\n",
    "(train_x, train_y), (val_x, val_y) = get_dataset_splits(train_metrics, val_metrics, num_samples)\n",
    "\n",
    "model = train_model(train_x, train_y, num_epochs = 1000)\n",
    "\n",
    "# using the model weights, get importance of each feature, and save to csv\n",
    "weights = model.weight.data.squeeze().tolist() \n",
    "features = keys\n",
    "feature_importance = {feature: weight for feature, weight in zip(features, weights)}\n",
    "df = pd.DataFrame(list(feature_importance.items()), columns=['Feature', 'Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl</td>\n",
       "      <td>0.024805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k_min_probs_0.05</td>\n",
       "      <td>0.283683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k_min_probs_0.1</td>\n",
       "      <td>-0.390490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k_min_probs_0.2</td>\n",
       "      <td>0.381211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k_min_probs_0.3</td>\n",
       "      <td>0.246895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k_min_probs_0.4</td>\n",
       "      <td>-0.033674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k_min_probs_0.5</td>\n",
       "      <td>-1.096520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>k_min_probs_0.6</td>\n",
       "      <td>0.597002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>k_max_probs_0.05</td>\n",
       "      <td>0.211646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>k_max_probs_0.1</td>\n",
       "      <td>-0.004144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k_max_probs_0.2</td>\n",
       "      <td>-0.284576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>k_max_probs_0.3</td>\n",
       "      <td>0.378435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>k_max_probs_0.4</td>\n",
       "      <td>-0.205955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>k_max_probs_0.5</td>\n",
       "      <td>-0.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>k_max_probs_0.6</td>\n",
       "      <td>0.138166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>zlib_ratio</td>\n",
       "      <td>0.048911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "0                ppl    0.024805\n",
       "1   k_min_probs_0.05    0.283683\n",
       "2    k_min_probs_0.1   -0.390490\n",
       "3    k_min_probs_0.2    0.381211\n",
       "4    k_min_probs_0.3    0.246895\n",
       "5    k_min_probs_0.4   -0.033674\n",
       "6    k_min_probs_0.5   -1.096520\n",
       "7    k_min_probs_0.6    0.597002\n",
       "8   k_max_probs_0.05    0.211646\n",
       "9    k_max_probs_0.1   -0.004144\n",
       "10   k_max_probs_0.2   -0.284576\n",
       "11   k_max_probs_0.3    0.378435\n",
       "12   k_max_probs_0.4   -0.205955\n",
       "13   k_max_probs_0.5   -0.080300\n",
       "14   k_max_probs_0.6    0.138166\n",
       "15        zlib_ratio    0.048911"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Dataset Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, loss = get_predictions(model, val_x, val_y)\n",
    "preds_train, loss_train = get_predictions(model, train_x, train_y)\n",
    "og_train = preds_train[train_y == 0]\n",
    "og_val = preds_train[train_y == 1]\n",
    "\n",
    "heldout_train = preds[val_y == 0]\n",
    "heldout_val = preds[val_y == 1]\n",
    "# alternate hypothesis: heldout_train < heldout_val\n",
    "\n",
    "if outliers == \"p-value\" or outliers == \"mean+p-value\":\n",
    "    heldout_train = remove_outliers(heldout_train, remove_frac = 0.05, outliers = \"randomize\")\n",
    "    heldout_val = remove_outliers(heldout_val, remove_frac = 0.05, outliers = \"randomize\")\n",
    "\n",
    "p_value_list = get_p_value_list(heldout_train, heldout_val, list_number_samples=[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0038565105899075196]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.6395527124404907: 100%|██████████| 1000/1000 [00:01<00:00, 631.87it/s]\n"
     ]
    }
   ],
   "source": [
    "num_random = 1 # How many random runs to do?\n",
    "num_samples = 50 # How many samples to use for training and validation?\n",
    "for i in range(num_random):\n",
    "    np.random.shuffle(train_metrics)\n",
    "    np.random.shuffle(val_metrics)\n",
    "    \n",
    "    # train a model by creating a train set and a held out set\n",
    "    (train_x, train_y), (val_x, val_y) = get_dataset_splits(train_metrics, val_metrics, num_samples)\n",
    "    \n",
    "    model = train_model(train_x, train_y, num_epochs = 1000)\n",
    "    preds, loss = get_predictions(model, val_x, val_y)\n",
    "    preds_train, loss_train = get_predictions(model, train_x, train_y)\n",
    "    og_train = preds_train[train_y == 0]\n",
    "    og_val = preds_train[train_y == 1]\n",
    "\n",
    "    heldout_train = preds[val_y == 0]\n",
    "    heldout_val = preds[val_y == 1]\n",
    "    # alternate hypothesis: heldout_train < heldout_val\n",
    "    \n",
    "    if outliers == \"p-value\" or outliers == \"mean+p-value\":\n",
    "        heldout_train = remove_outliers(heldout_train, remove_frac = 0.05, outliers = \"randomize\")\n",
    "        heldout_val = remove_outliers(heldout_val, remove_frac = 0.05, outliers = \"randomize\")\n",
    "\n",
    "    p_value_list = get_p_value_list(heldout_train, heldout_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.88661   , -0.3874984 , -0.79101145, -0.01261542,  0.46413305,\n",
       "       -0.13811317, -0.41857734, -0.3877732 , -0.14110729,  0.01094624,\n",
       "       -0.10262962, -0.7831085 ,  0.49617842, -0.20826474,  0.14064273,\n",
       "       -0.03651986,  1.8923998 ,  1.2640717 , -0.43924025,  0.06790521,\n",
       "       -0.19424674,  0.7400899 , -0.28640273,  2.265852  ,  1.4073684 ,\n",
       "       -0.07915518, -0.15063187, -0.8372953 ,  0.99971545,  0.05996384,\n",
       "        0.7860302 ,  0.3840671 , -0.10859922,  1.0737193 ,  0.5344206 ,\n",
       "        5.2956033 ,  0.23978582, -0.60437536,  1.1431992 , -0.63941866,\n",
       "        0.36124316, -1.4273818 ,  2.5828536 , -0.14944503,  0.70359766,\n",
       "        0.79249525, -0.04778824,  0.6618693 , -0.4120402 , -1.0859761 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heldout_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl</td>\n",
       "      <td>1.540416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k_min_probs_0.05</td>\n",
       "      <td>0.165446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k_min_probs_0.1</td>\n",
       "      <td>-0.637058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k_min_probs_0.2</td>\n",
       "      <td>0.328577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k_min_probs_0.3</td>\n",
       "      <td>0.423384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k_min_probs_0.4</td>\n",
       "      <td>0.048116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k_min_probs_0.5</td>\n",
       "      <td>-0.419963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>k_min_probs_0.6</td>\n",
       "      <td>-1.439138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>k_max_probs_0.05</td>\n",
       "      <td>2.402489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>k_max_probs_0.1</td>\n",
       "      <td>-3.714744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k_max_probs_0.2</td>\n",
       "      <td>-0.807581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>k_max_probs_0.3</td>\n",
       "      <td>1.166866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>k_max_probs_0.4</td>\n",
       "      <td>1.435386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>k_max_probs_0.5</td>\n",
       "      <td>-0.361273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>k_max_probs_0.6</td>\n",
       "      <td>0.141904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>zlib_ratio</td>\n",
       "      <td>0.183383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "0                ppl    1.540416\n",
       "1   k_min_probs_0.05    0.165446\n",
       "2    k_min_probs_0.1   -0.637058\n",
       "3    k_min_probs_0.2    0.328577\n",
       "4    k_min_probs_0.3    0.423384\n",
       "5    k_min_probs_0.4    0.048116\n",
       "6    k_min_probs_0.5   -0.419963\n",
       "7    k_min_probs_0.6   -1.439138\n",
       "8   k_max_probs_0.05    2.402489\n",
       "9    k_max_probs_0.1   -3.714744\n",
       "10   k_max_probs_0.2   -0.807581\n",
       "11   k_max_probs_0.3    1.166866\n",
       "12   k_max_probs_0.4    1.435386\n",
       "13   k_max_probs_0.5   -0.361273\n",
       "14   k_max_probs_0.6    0.141904\n",
       "15        zlib_ratio    0.183383"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4107766773806425,\n",
       " 0.36980158876864666,\n",
       " 0.04752750963490783,\n",
       " 0.11867921856676313,\n",
       " 0.37389410780078125,\n",
       " 0.22268208266235634,\n",
       " 0.06599884749456343,\n",
       " 0.020113088684094473,\n",
       " 0.011704511371354429,\n",
       " 0.00850177909203288,\n",
       " 0.042105663716985556,\n",
       " 0.008986398306532558,\n",
       " 0.0007218499858375457,\n",
       " 0.0003354090956819818,\n",
       " 0.001154656311558945,\n",
       " 0.0035443146056995225]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51663136, -0.1560684 ,  0.5157334 , -0.21615733,  0.52323455,\n",
       "        1.8859843 ,  0.511774  , -0.625938  , -0.99483424, -0.41054124,\n",
       "        1.4793929 ,  0.22003429, -0.9509558 ,  0.13129918, -0.22658832,\n",
       "       -1.0837651 , -0.5716633 , -0.11621578,  0.5561568 , -0.8394647 ,\n",
       "        0.4006781 , -0.09853537,  0.88472337,  0.8128087 ,  0.18891428,\n",
       "       -0.06233807, -0.15602644,  0.5759302 , -1.1861213 ,  0.3780684 ,\n",
       "       -0.85187584,  0.44206327, -1.2670323 ,  1.8527066 ,  0.04044168,\n",
       "       -0.7800655 ,  1.0773345 ,  1.4372088 ,  0.412579  , -0.24890132,\n",
       "       -0.2590168 , -0.1424504 ,  0.50125974,  0.04421322,  1.0535867 ,\n",
       "        0.71610206, -1.673247  , -0.5741055 , -1.6307869 ,  0.26277822],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heldout_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
